name: Review Pull Request with LlamaCPP

on:
  pull_request:
    types: [opened, synchronize, reopened]
    branches: ["main"]

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

jobs:
  llama-cpp:
    if: ${{ !contains(github.event.pull_request.labels.*.name, 'skip-ai-review') }}
    continue-on-error: true
    runs-on: ubuntu-latest
    name: LlamaCPP
    permissions:
      pull-requests: write
      contents: read
    timeout-minutes: 120
    env:
      LLAMA_CPP_COMMIT: 42ae10bbcd7b56f29a302c86796542a6dadf46c9
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Fetch branches and output the diff in this step
        run: |
          git fetch origin main:main
          git fetch origin pull/${{ github.event.pull_request.number }}/head:pr-branch
          mkdir -p /tmp/llama_review
          git diff main..pr-branch > /tmp/llama_review/diff.txt

      - name: Write prompt to file
        id: build_prompt
        run: |
          PR_TITLE=$(echo "${{ github.event.pull_request.title }}" | sed 's/[()]/\\&/g')
          DIFF_CONTENT=$(cat /tmp/llama_review/diff.txt)
          echo "<|im_start|>system
          You are a senior software engineer working ${{ github.event.repository.name }}, which has the following description: \"${{ github.event.repository.description }}\".
          You are currently reviewing a pull request titled \"$PR_TITLE\", from the branch \"${{ github.event.pull_request.head.ref }}\".<|im_end|>
          <|im_start|>user
          Write a high-quality review of the following changes:
          \`\`\`diff
          $DIFF_CONTENT
          \`\`\`
          <|im_end|>
          <|im_start|>assistant
          " > /tmp/llama_review/prompt.txt

      - name: Show Prompt
        run: cat /tmp/llama_review/prompt.txt

      - name: Cache LlamaCPP
        id: cache_llama_cpp
        uses: actions/cache@v4
        with:
          path: ~/.cache/llama.cpp/
          key: llama-cpp-${{ runner.os }}-${{ env.LLAMA_CPP_COMMIT }}

      - name: Clone and build LlamaCPP
        if: steps.cache_llama_cpp.outputs.cache-hit != 'true'
        run: |
          git clone https://github.com/ggerganov/llama.cpp.git
          cd llama.cpp
          git checkout ${{ env.LLAMA_CPP_COMMIT }}
          make -j llama-cli
          mkdir -p ~/.cache/llama.cpp/
          cp llama-cli ~/.cache/llama.cpp/
          curl -L -o ~/.cache/llama.cpp/model.gguf https://huggingface.co/unsloth/Qwen2.5-Coder-7B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-7B-Instruct-Q5_K_M.gguf

      - name: Copy LlamaCPP to /usr/local/bin/
        run: cp ~/.cache/llama.cpp/llama-cli /usr/local/bin/

      - name: Run LlamaCPP
        run: |
          PROMPT=$(cat /tmp/llama_review/prompt.txt)
          llama-cli \
            -m ~/.cache/llama.cpp/model.gguf \
            -p "$PROMPT" \
            -e \
            --ctx-size 32768 \
            -np 1 \
            -t -1 \
            -n -1 \
            --temp 0.5 \
            --top-p 0.9 \
            --min-p 0.1 \
            --top-k 0 \
            --no-display-prompt > /tmp/llama_review/response.txt

      - name: Show Response
        run: cat /tmp/llama_review/response.txt

      - name: Find Comment
        uses: peter-evans/find-comment@v3
        id: find_comment
        with:
          issue-number: ${{ github.event.pull_request.number }}
          comment-author: "github-actions[bot]"
          body-includes: "[end of text]"

      - name: Post or Update PR Review
        uses: peter-evans/create-or-update-comment@v4
        with:
          comment-id: ${{ steps.find_comment.outputs.comment-id }}
          issue-number: ${{ github.event.pull_request.number }}
          body-path: /tmp/llama_review/response.txt
          edit-mode: replace
